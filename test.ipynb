{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from OvertonApiUser import OvertonApiUser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"China\"] # , \"Sino\"\n",
    "year_list_1 = range(2015, 2025, 1)\n",
    "year_list_2 = range(2020, 2021, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword in keywords:\n",
    "    print(\"processing keyword: \" + keyword)\n",
    "    if(keyword != \"China\"):\n",
    "        year_list = year_list_2\n",
    "        for year in year_list:\n",
    "            print(\"processing year: \" + str(year))\n",
    "            time.sleep(2)\n",
    "            user = OvertonApiUser(keyword, year)\n",
    "            flag = user.initialRequest()\n",
    "            if(flag == False):\n",
    "                print(\"initial request failed\")\n",
    "                continue\n",
    "            flag = False\n",
    "            while(flag == False):\n",
    "                print(\"---next request---\")\n",
    "                flag = user.nextRequest()\n",
    "                time.sleep(2)\n",
    "    else:\n",
    "        year_list = year_list_1\n",
    "        for year in year_list:\n",
    "            print(\"processing year: \" + str(year))\n",
    "            if(year > 2014):\n",
    "                time.sleep(2)\n",
    "                user = OvertonApiUser(keyword, year, 1)\n",
    "                flag = user.initialRequest()\n",
    "                if(flag == False):\n",
    "                    print(\"initial request failed\")\n",
    "                    continue\n",
    "                flag = False\n",
    "                while(flag == False):\n",
    "                    print(\"---next request---\")\n",
    "                    flag = user.nextRequest()\n",
    "                    time.sleep(2)\n",
    "\n",
    "                time.sleep(2)\n",
    "                user = OvertonApiUser(keyword, year, 0)\n",
    "                flag = user.initialRequest()\n",
    "                if(flag == False):\n",
    "                    print(\"initial request failed\")\n",
    "                    continue\n",
    "                flag = False\n",
    "                while(flag == False):\n",
    "                    print(\"---next request---\")\n",
    "                    flag = user.nextRequest()\n",
    "                    time.sleep(2)\n",
    "\n",
    "            else:\n",
    "                time.sleep(2)\n",
    "                user = OvertonApiUser(keyword, year)\n",
    "                flag = user.initialRequest()\n",
    "                if(flag == False):\n",
    "                    print(\"initial request failed\")\n",
    "                    continue\n",
    "                flag = False\n",
    "                while(flag == False):\n",
    "                    print(\"---next request---\")\n",
    "                    flag = user.nextRequest()\n",
    "                    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_list = [\"China\"]\n",
    "for folder in data_folder_list:\n",
    "    policy_doc_set = set()\n",
    "    data_folder = \"./results/\" + folder + \"/\"\n",
    "    print(\"Processing \" + data_folder)\n",
    "    count = 0\n",
    "    for file in tqdm(os.listdir(data_folder)):\n",
    "        if file.endswith(\".xlsx\") : # and file.startswith(\"year_2021_\")\n",
    "            file_path = os.path.join(data_folder, file)\n",
    "            try:\n",
    "                df = pd.read_excel(file_path)\n",
    "                for i in range(0, df.shape[0]):\n",
    "                    policy_doc_set.add(df.loc[i, \"policy_document_id\"])\n",
    "                    count = count + df.loc[i, \"grouped_pdf_ids_in_result_count\"]\n",
    "            except:\n",
    "                print(\"Error reading file: \" + file_path)\n",
    "\n",
    "    print(\"Total number of documents: \" + str(len(policy_doc_set)))\n",
    "    print(\"Total number of documents: \" + str((count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(\"./results/China/year_1895_page_1_query_China.xlsx\")\n",
    "df2 = pd.read_excel(\"./results/China/year_1897_page_1_query_China.xlsx\")\n",
    "\n",
    "df_merged = pd.concat([df1, df2], ignore_index=True)\n",
    "df_merged.to_csv(\"./results/merged_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_list = [\"China\", \"Chinese\", \"Sino\"] # \"China\", \"Chinese\", \"Sino\"\n",
    "for folder in data_folder_list:\n",
    "    data_folder = \"./results/\" + folder + \"/\"\n",
    "    print(\"Processing \" + data_folder)\n",
    "    df = pd.DataFrame()\n",
    "    for file in tqdm(os.listdir(data_folder)):\n",
    "        if file.endswith(\".xlsx\"):\n",
    "            file_path = os.path.join(data_folder, file)\n",
    "            try:\n",
    "                df = pd.concat([df, pd.read_excel(file_path)])\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_path}: {e}\")\n",
    "    df.to_csv(data_folder + \"merged.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
